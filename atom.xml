<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>xhs</title>
  
  <subtitle>西红柿花园</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2019-01-09T09:39:32.595Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>ydcSelf</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>动态代理</title>
    <link href="http://yoursite.com/posts/41590/"/>
    <id>http://yoursite.com/posts/41590/</id>
    <published>2019-01-09T09:26:02.000Z</published>
    <updated>2019-01-09T09:39:32.595Z</updated>
    
    <content type="html"><![CDATA[<p>##什么是代理<br>代理是一种常用的设计模式，其目的就是为其他对象提供一个代理以控制对某个对象的访问。代理类负责为委托类预处理消息，过滤消息并转发消息，以及进行消息被委托类执行后的后续处理。</p><p>##jdk动态代理</p><p>###原理<br>jdk动态代理基于接口实现，其目的是在动态运行时，创建一个代理对象，让其去实现接口中的方法，并且可以在对该方法进行一些修饰（增强功能，打印日志等，spring aop就是运用动态代理实现的）。</p><p>###步骤<br>1、需要动态代理的接口</p><pre><code>public interface person {    public String sayHello(String name);}</code></pre><p>2、需要代理的对象</p><pre><code>public class student implements person {    @Override    public String sayHello(String name) {        return &quot;hello,my name is&quot;+name;    }}</code></pre><p>3、实际处理的类</p><pre><code>import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;import java.lang.reflect.Proxy;import net.sf.cglib.proxy.Enhancer;import net.sf.cglib.proxy.MethodInterceptor;import net.sf.cglib.proxy.MethodProxy;public class invactionhandlerimp implements InvocationHandler{    private Object student;    public invactionhandlerimp(Object student) {        super();        this.student = student;    }    @Override    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {        System.out.println(&quot;调用之前，我要说啥&quot;);        System.out.println(&quot;Method&quot;+method);        Object returnValue = method.invoke(this.student, args);        System.out.println(&quot;调用之后，我要做什么&quot;);        return returnValue;    }    public static void main(String[] args) {        person student = new student();        //传入代理的对象        invactionhandlerimp demo = new invactionhandlerimp(new student());        //将代理接口指向实际处理的对象，通过Proxy.newProxyInstance可以创建出需要的代理对象        person person = (person) Proxy.newProxyInstance(student.getClass().getClassLoader(),student.getClass().getInterfaces(),demo);        String name = student.getClass().getName();        System.out.println(name);        System.out.println(person.sayHello(&quot;ydc&quot;));    }}</code></pre><p>4、输出内容</p><pre><code>com.sun.proxy.$Proxy0调用之前，我要说啥Methodpublic abstract java.lang.String person.sayHello(java.lang.String)调用之后，我要做什么hello,my name isydc</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;##什么是代理&lt;br&gt;代理是一种常用的设计模式，其目的就是为其他对象提供一个代理以控制对某个对象的访问。代理类负责为委托类预处理消息，过滤消息并转发消息，以及进行消息被委托类执行后的后续处理。&lt;/p&gt;
&lt;p&gt;##jdk动态代理&lt;/p&gt;
&lt;p&gt;###原理&lt;br&gt;jdk动态代理
      
    
    </summary>
    
      <category term="java" scheme="http://yoursite.com/categories/java/"/>
    
    
      <category term="tags" scheme="http://yoursite.com/tags/tags/"/>
    
  </entry>
  
  <entry>
    <title>多线程爬取图片</title>
    <link href="http://yoursite.com/posts/48904/"/>
    <id>http://yoursite.com/posts/48904/</id>
    <published>2018-12-26T02:55:00.000Z</published>
    <updated>2018-12-27T07:17:43.912Z</updated>
    
    <content type="html"><![CDATA[<h2 id="在参考了很多网上很多大牛的技术，也想着自己写一个博客。之前写了一个爬虫工具，就拿这个来写吧。-首先感谢-崔庆才-http-cuiqingcai-com-3179-html-文章写的都挺好的。"><a href="#在参考了很多网上很多大牛的技术，也想着自己写一个博客。之前写了一个爬虫工具，就拿这个来写吧。-首先感谢-崔庆才-http-cuiqingcai-com-3179-html-文章写的都挺好的。" class="headerlink" title="在参考了很多网上很多大牛的技术，也想着自己写一个博客。之前写了一个爬虫工具，就拿这个来写吧。 首先感谢 崔庆才 http://cuiqingcai.com/3179.html 文章写的都挺好的。"></a>在参考了很多网上很多大牛的技术，也想着自己写一个博客。之前写了一个爬虫工具，就拿这个来写吧。 首先感谢 崔庆才 <a href="http://cuiqingcai.com/3179.html" target="_blank" rel="noopener">http://cuiqingcai.com/3179.html</a> 文章写的都挺好的。</h2><h1 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h1><p>Python3.7 </p><h1 id="第三方库"><a href="#第三方库" class="headerlink" title="第三方库"></a>第三方库</h1><p>requests<br>BeautifulSoup  </p><h1 id="安装方法："><a href="#安装方法：" class="headerlink" title="安装方法："></a>安装方法：</h1><p>pip install requests<br>pip install beautifulsoup4</p><h1 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h1><p>找到目标网址，根据获取的url进行解析遍历，在生成本地的html文本。从文本中获取你想要的资源，通过python来实现下载。</p><h1 id="目标网址"><a href="#目标网址" class="headerlink" title="目标网址"></a>目标网址</h1><p>（一个很羞涩的网址）  </p><p><a href="http://mzitu.com" target="_blank" rel="noopener">http://mzitu.com </a></p><h1 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h1><ol><li><p>首先获取网址  </p><pre><code> Hostreferer = {     &#39;User-Agent&#39;: &#39;Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1)&#39;,     &#39;Referer&#39;: &#39;http://www.mzitu.com&#39; } start_html = requests.get(&#39;http://www.mzitu.com&#39;, headers=Hostreferer)   soup = BeautifulSoup(start_html.text, &quot;html.parser&quot;) print(soup) `</code></pre><p>可以查看采集到的页面信息。</p></li><li><p>但是这个页面有很多页，并且每一页有单独的分类图片，随机选几页可以看到url都是一样的<a href="http://www.mzitu.com/page/num，后面是页数。" target="_blank" rel="noopener">http://www.mzitu.com/page/num，后面是页数。</a> </p><pre><code> start_html = requests.get(&#39;http://www.mzitu.com/page/1&#39;, headers=Hostreferer)     soup = BeautifulSoup(start_html.text, &quot;html.parser&quot;)     all_a = soup.find(&#39;div&#39;, class_=&#39;postlist&#39;).find_all(         &#39;a&#39;, target=&#39;_blank&#39;) for a in all_a:         print(a)</code></pre><p>可以看下爬取到这一页中每个分类的连接</p></li><li><p>现在开始爬取每个分类中的图片,从上个获取到的a标签中获取需要的url   </p><pre><code> print(&quot;准备扒取：&quot; + title)   html = requests.get(a[&#39;href&#39;], headers=Hostreferer) mess = BeautifulSoup(html.text, &quot;html.parser&quot;) pic_max = mess.find_all(&#39;span&#39;) pic_max = pic_max[10].text  # 最大页数 for num in range(1, int(pic_max) + 1):     pic = href + &#39;/&#39; + str(num)     html = requests.get(pic, headers=Hostreferer)     mess = BeautifulSoup(html.text, &quot;html.parser&quot;)     pic_url = mess.find(&#39;img&#39;, alt=a.get_text())     print(pic_url[&#39;src&#39;])     html = requests.get(pic_url[&#39;src&#39;], headers=Picreferer)     file_name = pic_url[&#39;src&#39;].split(r&#39;/&#39;)[-1]     f = open(file_name, &#39;wb&#39;)     f.write(html.content)     f.close() print(&#39;完成&#39;)</code></pre></li><li><p>我们把图片按照每个分类的名称存储，<br>import os</p><pre><code> path = &#39;F:\\meitu\&#39; if(os.path.exists(path + title.strip().replace(&#39;?&#39;, &#39;&#39;))):     # print(&#39;目录已存在&#39;)     flag = 1 else:     os.makedirs(path + title.strip().replace(&#39;?&#39;, &#39;&#39;))     flag = 0 os.chdir(path + title.strip().replace(&#39;?&#39;, &#39;&#39;)) if(flag == 1 and len(os.listdir(path + title.strip().replace(&#39;?&#39;, &#39;&#39;))) &gt;= int(pic_max)):     print(&#39;已经保存完毕，跳过&#39;)     return 1</code></pre></li></ol><h2 id="多线程操作"><a href="#多线程操作" class="headerlink" title="多线程操作"></a>多线程操作</h2><p>引入from multiprocessing import Pool<br>将下载的方法放在多线程中操作</p><pre><code>pool = Pool(processes=20)  pool.apply_async(DownLoad, args=(                    href, title, path, Hostreferer, Picreferer))</code></pre><h2 id="完整代码"><a href="#完整代码" class="headerlink" title="完整代码"></a>完整代码</h2><pre><code>import requestsfrom bs4 import BeautifulSoupimport osfrom Thread_demo import *from multiprocessing import Pooldef max_page(all_url, Hostreferer):    max_page = 0    start_html = requests.get(all_url, headers=Hostreferer)    soup = BeautifulSoup(start_html.text, &quot;html.parser&quot;)    page = soup.find_all(&#39;a&#39;, class_=&#39;page-numbers&#39;)    max_page = page[-2].text    return max_pagedef Down(url):    path = &#39;E:/meitu/&#39;    Hostreferer = {        &#39;User-Agent&#39;: &#39;Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1)&#39;,        &#39;Referer&#39;: &#39;http://www.mzitu.com&#39;    }    Picreferer = {        &#39;User-Agent&#39;: &#39;Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1)&#39;,        &#39;Referer&#39;: &#39;http://i.meizitu.net&#39;    }def DownLoad(href, title, path, Hostreferer, Picreferer):    print(&quot;准备扒取：&quot; + title)    # win不能创建带？的目录    if(os.path.exists(path + title.strip().replace(&#39;?&#39;, &#39;&#39;))):        # print(&#39;目录已存在&#39;)        flag = 1    else:        os.makedirs(path + title.strip().replace(&#39;?&#39;, &#39;&#39;))        flag = 0    os.chdir(path + title.strip().replace(&#39;?&#39;, &#39;&#39;))    html = requests.get(href, headers=Hostreferer)    mess = BeautifulSoup(html.text, &quot;html.parser&quot;)    pic_max = mess.find_all(&#39;span&#39;)    pic_max = pic_max[10].text  # 最大页数    if(flag == 1 and len(os.listdir(path + title.strip().replace(&#39;?&#39;, &#39;&#39;))) &gt;= int(pic_max)):        print(&#39;已经保存完毕，跳过&#39;)        return 1    for num in range(1, int(pic_max) + 1):        pic = href + &#39;/&#39; + str(num)        html = requests.get(pic, headers=Hostreferer)        mess = BeautifulSoup(html.text, &quot;html.parser&quot;)        pic_url = mess.find(&#39;img&#39;, alt=title)        print(pic_url[&#39;src&#39;])        # exit(0)        html = requests.get(pic_url[&#39;src&#39;], headers=Picreferer)        file_name = pic_url[&#39;src&#39;].split(r&#39;/&#39;)[-1]        f = open(file_name, &#39;wb&#39;)        f.write(html.content)        f.close()    print(&#39;完成&#39;)if __name__ == &#39;__main__&#39;:    if (os.name == &#39;nt&#39;):        print(u&#39;你正在使用win平台&#39;)    else:        print(u&#39;你正在使用linux平台&#39;)    Hostreferer = {        &#39;User-Agent&#39;: &#39;Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1)&#39;,        &#39;Referer&#39;: &#39;http://www.mzitu.com&#39;    }    Picreferer = {        &#39;User-Agent&#39;: &#39;Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1)&#39;,        &#39;Referer&#39;: &#39;http://i.meizitu.net&#39;    }    all_url = &#39;http://www.mzitu.com&#39;    same_url = &#39;http://www.mzitu.com/page/&#39;    path = &#39;E:/meitu/&#39;    max_page = max_page(all_url, Hostreferer)    # 线程池中线程数    pool = Pool(processes=20)    for n in range(1, int(max_page) + 1):        ul = same_url + str(n)        start_html = requests.get(ul, headers=Hostreferer)        soup = BeautifulSoup(start_html.text, &quot;html.parser&quot;)        all_a = soup.find(&#39;div&#39;, class_=&#39;postlist&#39;).find_all(            &#39;a&#39;, target=&#39;_blank&#39;)        for a in all_a:            print(a)            title = a.get_text()            if (title != &#39;&#39;):                href = a[&#39;href&#39;]                pool.apply_async(DownLoad, args=(                    href, title, path, Hostreferer, Picreferer))    pool.close()    pool.join()    print(&#39;所有图片完成&#39;)</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;在参考了很多网上很多大牛的技术，也想着自己写一个博客。之前写了一个爬虫工具，就拿这个来写吧。-首先感谢-崔庆才-http-cuiqingcai-com-3179-html-文章写的都挺好的。&quot;&gt;&lt;a href=&quot;#在参考了很多网上很多大牛的技术，也想着自己写一个博
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>互联网经济</title>
    <link href="http://yoursite.com/posts/24187/"/>
    <id>http://yoursite.com/posts/24187/</id>
    <published>2018-12-25T03:11:52.000Z</published>
    <updated>2018-12-25T09:13:04.444Z</updated>
    
    <content type="html"><![CDATA[<h3 id="互联网经济"><a href="#互联网经济" class="headerlink" title="互联网经济"></a>互联网经济</h3><ul><li><p>互联网经济是基于互联网所产生的经济活动的总和，在当今发展阶段主要 包括电子商务、互联网金融(ITFIN)、即时通讯、搜索引擎和网络游戏五大类型。互联网经济是信息网络化时代产生的一种崭新的经济现象。</p></li><li><p>在互联网经济时代，经济主体的生产、交换、分配、消费等经济活动，以及金融机构和政府职能部门等主体的经济行为，都越来越多地依赖信息网络，不仅要从网络上获取大量经济信息，依靠网络进行预测和决策，而且许多交易行为也直接在信息网络上 进行。</p></li></ul><h3 id="阿里巴巴和淘宝"><a href="#阿里巴巴和淘宝" class="headerlink" title="阿里巴巴和淘宝"></a>阿里巴巴和淘宝</h3><blockquote><p>总部位于杭州的阿里巴巴集团，其旗下的阿里巴巴B2B网站是全球最大的网上贸易市场。良好的定位，稳固的结构，优秀的服务使阿里巴巴B2B网站成为全球首家拥有210万商人的电子商务网站，成为全球商人网络推广的首选网站，被商人们评为”最受欢迎的B2B网站”。<br>淘宝网是阿里巴巴集团旗下主营B2C、C2C业务的专业网站。淘宝网自2003年5月推出以来，短短五年内迅速发展成为亚洲最大的网络零售商圈。</p></blockquote><blockquote><p>截至2008年第一季度，淘宝网已为社会提供超过30万的直接就业岗位，并创造了60万的间接就业岗位。在不久前的淘宝网五周年庆典上，阿里巴巴集团董事局主席马云表示，阿里巴巴集团将向淘宝网追加20亿元人民币投资，使淘宝网5年内超越eBay全球和亚马逊，10年内超越沃尔玛全球，成为全球零售业老大。</p></blockquote><p>###网络经济(Network_Economy_)的介绍?###</p><blockquote><p>网络经济(Network Economy ):国际互联网引发的经济革命</p></blockquote><blockquote><p>众所周知,知识经济是以电脑、卫星通信、光缆通信和数码技术等为标志的现代信息技术和全球信息网络”爆炸性”发展的必然结果。在知识经济条件下,现实经济运行主要表现为信息化和全球化两大趋势。这两种趋势的出现无不与信息技术和信息网络的发展密切相关。</p></blockquote><blockquote><p>现代信息技术的发展,大大提高了人们处理信息的能力和利用信息的效率,加速了科技开发与创新的步伐,加快了科技成果向现实生产力转化的速度,从而使知识在经济增长中的贡献程度空前提高; 全球信息网络的出现和发展,进一步加快了信息在全球范围内的传递和扩散,使传统的国家、民族界限变得日益模糊,使整个世界变成了一个小小的”地球村”,从而使世界经济发展呈现出明显的全球化趋势。</p></blockquote><blockquote><p>因此,知识经济实质上是一种以现代信息技术为核心的全球网络经济。</p></blockquote><p><a href="http://baike.so.com/doc/1256916-1329280.html" title="copy" target="_blank" rel="noopener">出处</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;互联网经济&quot;&gt;&lt;a href=&quot;#互联网经济&quot; class=&quot;headerlink&quot; title=&quot;互联网经济&quot;&gt;&lt;/a&gt;互联网经济&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;互联网经济是基于互联网所产生的经济活动的总和，在当今发展阶段主要 包括电子商务、互联网金融(ITF
      
    
    </summary>
    
      <category term="categories" scheme="http://yoursite.com/categories/categories/"/>
    
    
      <category term="tags" scheme="http://yoursite.com/tags/tags/"/>
    
  </entry>
  
</feed>
